{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1119 10:56:03.545968 140508951906112 deprecation_wrapper.py:119] From /home/cartobot/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import keras \n",
    "from keras.models import load_model\n",
    "import keras.layers as layers\n",
    "from segmentation_models import Unet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Activation, Dense\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "def swish(x):\n",
    "        return (K.sigmoid(x) * x)\n",
    "\n",
    "get_custom_objects().update({'swish': Activation(swish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 10:56:03.565601 140508951906112 deprecation_wrapper.py:119] From /home/cartobot/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1119 10:56:03.678587 140508951906112 deprecation_wrapper.py:119] From /home/cartobot/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1119 10:56:03.692745 140508951906112 deprecation_wrapper.py:119] From /home/cartobot/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1119 10:56:03.693513 140508951906112 deprecation_wrapper.py:119] From /home/cartobot/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1119 10:56:05.035643 140508951906112 deprecation_wrapper.py:119] From /home/cartobot/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1119 10:56:05.095597 140508951906112 deprecation_wrapper.py:119] From /home/cartobot/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1119 10:56:13.166697 140508951906112 deprecation_wrapper.py:119] From /home/cartobot/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('models1/reentrenamiento.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 10:56:22.184878 140508951906112 deprecation_wrapper.py:119] From /home/cartobot/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1119 10:56:22.196498 140508951906112 deprecation.py:323] From /home/cartobot/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from segmentation_models import Unet\n",
    "from keras.optimizers import Adam\n",
    "import segmentation_models as sm\n",
    "from segmentation_models.losses import bce_jaccard_loss, bce_dice_loss\n",
    "model.compile(optimizer = Adam(),loss=bce_jaccard_loss, metrics=[sm.metrics.IOUScore(), sm.metrics.FScore()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from albumentations import (Blur, Compose, HorizontalFlip, HueSaturationValue,\n",
    "                            IAAEmboss, IAASharpen, JpegCompression, OneOf,\n",
    "                            RandomBrightness, RandomBrightnessContrast,\n",
    "                            RandomContrast, RandomCrop, RandomGamma,\n",
    "                            RandomRotate90, RGBShift, ShiftScaleRotate,\n",
    "                            Transpose, VerticalFlip, ElasticTransform, GridDistortion, OpticalDistortion)\n",
    " \n",
    "def rgb2gray(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray.reshape((512,512,1))\n",
    "\n",
    "def listdir_fullpath(d):\n",
    "    return [os.path.join(d, f) for f in os.listdir(d)]\n",
    "\n",
    "\n",
    "def removeAlphaChannel(image):\n",
    "    return image[:,:,:3]\n",
    "\n",
    "import albumentations as albu\n",
    "from albumentations import Resize\n",
    "\n",
    "class DataGeneratorFolder(Sequence):\n",
    "    def __init__(self, root_dir=r'../data/val_test', image_folder='img/', mask_folder='masks/', \n",
    "                 batch_size=1, image_size=512, nb_y_features=1, \n",
    "                 augmentation=None,\n",
    "                 suffle=True):\n",
    "        self.image_filenames = listdir_fullpath(os.path.join(root_dir, image_folder))\n",
    "        self.mask_names = listdir_fullpath(os.path.join(root_dir, mask_folder))\n",
    "        self.batch_size = batch_size\n",
    "        self.currentIndex = 0\n",
    "        self.augmentation = augmentation\n",
    "        self.image_size = image_size\n",
    "        self.nb_y_features = nb_y_features\n",
    "        self.indexes = None\n",
    "        self.suffle = suffle\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Calculates size of batch\n",
    "        \"\"\"\n",
    "        return int(np.ceil(len(self.image_filenames) / (self.batch_size)))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\"\"\"\n",
    "        if self.suffle==True:\n",
    "            self.image_filenames, self.mask_names = shuffle(self.image_filenames, self.mask_names)\n",
    "        \n",
    "    def read_image_mask(self, image_name, mask_name):\n",
    "        #return removeAlphaChannel(imread(image_name))/255, rgb2gray(imread(mask_name)).astype(np.int8)\n",
    "        return (removeAlphaChannel(imread(image_name))/255).astype(np.float32), (imread(mask_name, as_gray=True)<1).astype(np.int8)\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "            # Generate indexes of the batch\n",
    "            data_index_min = int(index*self.batch_size)\n",
    "            data_index_max = int(min((index+1)*self.batch_size, len(self.image_filenames)))\n",
    "\n",
    "            indexes = self.image_filenames[data_index_min:data_index_max]\n",
    "\n",
    "            this_batch_size = len(indexes) # The last batch can be smaller than the others\n",
    "\n",
    "            # Defining dataset\n",
    "            X = np.empty((this_batch_size, self.image_size, self.image_size, 3), dtype=np.float32)\n",
    "            y = np.empty((this_batch_size, self.image_size, self.image_size, self.nb_y_features), dtype=np.uint8)\n",
    "\n",
    "            for i, sample_index in enumerate(indexes):            \n",
    "                X_sample, y_sample = self.read_image_mask(self.image_filenames[index * self.batch_size + i], self.mask_names[index * self.batch_size + i])\n",
    "\n",
    "\n",
    "                # if augmentation is defined, we assume its a train set\n",
    "\n",
    "                if self.augmentation is not None:\n",
    "\n",
    "                    # Augmentation code\n",
    "                    a = self.augmentation(image_size=self.image_size)\n",
    "                    augmented = a(image=X_sample, mask=y_sample)\n",
    "                    image_augm = augmented['image']\n",
    "                    #image_augm = X_sample\n",
    "                    mask_augm = augmented['mask'].reshape(self.image_size, self.image_size, self.nb_y_features)\n",
    "                    #mask_augm = y_sample.reshape(self.image_size, self.image_size, self.nb_y_features)\n",
    "                    X[i, ...] = np.clip(image_augm, a_min = 0, a_max=1)\n",
    "                    y[i, ...] = mask_augm\n",
    "\n",
    "                # if augmentation isnt defined, we assume its a test set. \n",
    "                # Because test images can have different sizes we resize it to be divisable by 32\n",
    "                elif self.augmentation is None and self.batch_size == 1:\n",
    "                    X_sample, y_sample = self.read_image_mask(self.image_filenames[index * 1 + i], \n",
    "                                                          self.mask_names[index * 1 + i])\n",
    "                    #augmented = Resize(height=(X_sample.shape[0]//32)*32, width=(X_sample.shape[1]//32)*32)(image = X_sample, mask = y_sample)\n",
    "                    #X_sample, y_sample = augmented['image'], augmented['mask']\n",
    "\n",
    "                    return X_sample.reshape(1, X_sample.shape[0], X_sample.shape[1], 3).astype(np.float32),\\\n",
    "                           y_sample.reshape(1, X_sample.shape[0], X_sample.shape[1], self.nb_y_features).astype(np.uint8)\n",
    "\n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "test_generator = DataGeneratorFolder(root_dir = './test',\n",
    "                           image_folder = 'input/',\n",
    "                           mask_folder = 'output/',\n",
    "                                   batch_size=1,\n",
    "                                   nb_y_features = 1, augmentation = None,suffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true_in, y_pred_in):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "\n",
    "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
    "\n",
    "    intersection = temp1[0]\n",
    "\n",
    "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
    "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "  \n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    intersection[intersection == 0] = 1e-9\n",
    "    \n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    iou = intersection / union\n",
    "    return iou\n",
    "\n",
    "def plot_mask_gt_image(mask, groud_truth, img):\n",
    "    fig, axs = plt.subplots(1,3, figsize=(20,10))\n",
    "    axs[0].imshow(mask, cmap=\"Blues\")\n",
    "    axs[1].imshow(groud_truth, cmap=\"Blues\")\n",
    "    axs[2].imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    y_pred_in = y_pred_in\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.50447\n",
      "mean iou_score: 0.57134\n",
      "mean f1-score: 0.70542\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test_generator)\n",
    "metrics=[sm.metrics.IOUScore(), sm.metrics.FScore()]\n",
    "print(\"Loss: {:.5}\".format(scores[0]))\n",
    "for metric, value in zip(metrics, scores[1:]):\n",
    "    print(\"mean {}: {:.5}\".format(metric.__name__, value))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBTENER IMAGENES CON RESULTADOS:\n",
    "Xtest, y_test  = test_generator.__getitem__(25) #PROBAR DIFERENTES ITEMS: ej, 25, 30, 1000, 30000 (para obtener diferentes resultados)\n",
    "predicted = model.predict(np.expand_dims(Xtest[0], axis=0)).reshape(512, 512)\n",
    "print('IOU', iou_metric(y_test[0].reshape(512, 512), predicted))\n",
    "\n",
    "plt.imshow(predicted)\n",
    "plt.show()\n",
    "plt.imshow(y_test[0].reshape((512,512)))\n",
    "plt.show()\n",
    "plt.imshow(Xtest[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
