{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "base_dir = 'tiles'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 8, 8, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 65,058,625\n",
      "Trainable params: 65,058,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "img_width, img_height = 256, 256\n",
    "conv_base= VGG16(weights=None, include_top=False, input_shape=(img_width,img_height,3))\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=4096,activation=\"relu\")) #si no entrena bien: init = 'he_normal'    #he_uniform\n",
    "model.add(layers.Dense(units=4096,activation=\"relu\"))\n",
    "model.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-4), metrics=['acc']) #si es demasiado lento, Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 484048 images belonging to 2 classes.\n",
      "Found 26893 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1. /255)\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255, rotation_range=25, \n",
    "                                   width_shift_range=0.1, height_shift_range=0.1, \n",
    "                                   zoom_range=0.1, horizontal_flip=True, vertical_flip=True, \n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(256, 256),\n",
    "                                                    batch_size=50, class_mode='binary')\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir, target_size=(256, 256), \n",
    "                                                              batch_size=50,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.03952376, 0.96337163])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_steps_per_epoch = np.math.ceil(train_generator.samples / train_generator.batch_size)\n",
    "validation_steps_per_epoch = np.math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
    "\n",
    "#teniendo en cuenta el desbalanceo de clases\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(train_generator.classes), train_generator.classes)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/miguelmmanso/anaconda3/envs/pruebas/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/50\n",
      "9681/9681 [==============================] - 4988s 515ms/step - loss: 0.5138 - acc: 0.7290 - val_loss: 0.4430 - val_acc: 0.7851\n",
      "Epoch 2/50\n",
      "9681/9681 [==============================] - 4960s 512ms/step - loss: 0.4188 - acc: 0.8000 - val_loss: 0.3853 - val_acc: 0.8152\n",
      "Epoch 3/50\n",
      "9681/9681 [==============================] - 4958s 512ms/step - loss: 0.3933 - acc: 0.8117 - val_loss: 0.3899 - val_acc: 0.8208\n",
      "Epoch 4/50\n",
      "9681/9681 [==============================] - 4959s 512ms/step - loss: 0.3778 - acc: 0.8184 - val_loss: 0.3661 - val_acc: 0.8282\n",
      "Epoch 5/50\n",
      "9681/9681 [==============================] - 4959s 512ms/step - loss: 0.3674 - acc: 0.8223 - val_loss: 0.3650 - val_acc: 0.8269\n",
      "Epoch 6/50\n",
      "9681/9681 [==============================] - 4965s 513ms/step - loss: 0.3584 - acc: 0.8251 - val_loss: 0.3695 - val_acc: 0.8236\n",
      "Epoch 7/50\n",
      "9681/9681 [==============================] - 4968s 513ms/step - loss: 0.3522 - acc: 0.8267 - val_loss: 0.3729 - val_acc: 0.8257\n",
      "Epoch 8/50\n",
      "9681/9681 [==============================] - 4970s 513ms/step - loss: 0.3465 - acc: 0.8291 - val_loss: 0.3492 - val_acc: 0.8298\n",
      "Epoch 9/50\n",
      "9681/9681 [==============================] - 4968s 513ms/step - loss: 0.3427 - acc: 0.8308 - val_loss: 0.3519 - val_acc: 0.8301\n",
      "Epoch 10/50\n",
      "9681/9681 [==============================] - 4970s 513ms/step - loss: 0.3395 - acc: 0.8319 - val_loss: 0.3887 - val_acc: 0.8235\n",
      "Epoch 11/50\n",
      "9681/9681 [==============================] - 4969s 513ms/step - loss: 0.3364 - acc: 0.8332 - val_loss: 0.3598 - val_acc: 0.8321\n",
      "Epoch 12/50\n",
      "9681/9681 [==============================] - 4967s 513ms/step - loss: 0.3340 - acc: 0.8343 - val_loss: 0.3414 - val_acc: 0.8326\n",
      "Epoch 13/50\n",
      "9681/9681 [==============================] - 4960s 512ms/step - loss: 0.3314 - acc: 0.8353 - val_loss: 0.3396 - val_acc: 0.8351\n",
      "Epoch 14/50\n",
      "9681/9681 [==============================] - 5019s 518ms/step - loss: 0.3299 - acc: 0.8357 - val_loss: 0.3442 - val_acc: 0.8341\n",
      "Epoch 15/50\n",
      "9681/9681 [==============================] - 4969s 513ms/step - loss: 0.3272 - acc: 0.8374 - val_loss: 0.3436 - val_acc: 0.8340\n",
      "Epoch 16/50\n",
      " 624/9681 [>.............................] - ETA: 1:15:31 - loss: 0.3224 - acc: 0.8376"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, steps_per_epoch= train_steps_per_epoch, \n",
    "                              epochs=50, validation_data=validation_generator,\n",
    "                              validation_steps=validation_steps_per_epoch, class_weight=class_weights) #callbacks = [tensorboard]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.figure(figsize=(20,10))\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) +1) \n",
    "plt.rcParams.update({'font.size':18})\n",
    "plt.plot(epochs, acc, 'bo--', color='r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'bo--', color='b', label='Validation acc')\n",
    "plt.legend()\n",
    "plt.plot(epochs, loss, color= 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, color=\"b\", label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models1/vgg16_noweights-2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EARLY STOPPING\n",
    "#from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1,\n",
    "#                             save_best_only=True, save_weights_only=False, mode='auto', \n",
    "#                             period=5)\n",
    "#early = EarlyStopping(monitor='val_acc', min_delta=0, patience=50, verbose=1, mode='auto')\n",
    "\n",
    "#hist = model.fit_generator(steps_per_epoch=100,generator=traindata, \n",
    "#                           validation_data= testdata, validation_steps=10,epochs=100,\n",
    "#                           callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.preprocessing import imageimg = image.load_img(\"image.jpeg\",target_size=(224,224))\n",
    "#img = np.asarray(img)\n",
    "#plt.imshow(img)\n",
    "#img = np.expand_dims(img, axis=0)from keras.models import load_model\n",
    "#saved_model = load_model(\"vgg16_1.h5\")output = saved_model.predict(img)\n",
    "#if output[0][0] > output[0][1]:\n",
    "#    print(\"Road\")\n",
    "#else:\n",
    "#    print('No Road')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
